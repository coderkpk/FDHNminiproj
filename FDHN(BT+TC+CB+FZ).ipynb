{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderkpk/FDHNminiproj/blob/main/FDHN(BT%2BTC%2BCB%2BFZ).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofbo-d_1aQP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecfc513-4d5a-4636-81f3-09aca715aa16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version : 2.6.0+cu124\n",
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "<ipython-input-1-721fcd55a174>:98: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  train_label = torch.nn.functional.one_hot(torch.tensor(train_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Fixing the randomness of CUDA.\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"PyTorch Version : {}\".format(torch.__version__))\n",
        "print(DEVICE)\n",
        "\n",
        "\n",
        "worksapce = '/content/drive/MyDrive/liar/'\n",
        "model_save = 'TC+TC+CB+FZ.pt'\n",
        "model_name = 'TC+TC+CB+FZ'\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "num_classes = 6\n",
        "padding_idx = 0\n",
        "metadata_each_dim = 10\n",
        "\n",
        "\n",
        "col = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
        "\n",
        "label_map = {0: 'pants-fire', 1: 'false', 2: 'barely-true', 3: 'half-true', 4: 'mostly-true', 5: 'true'}\n",
        "label_convert = {'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true':5}\n",
        "\n",
        "train_data = pd.read_csv(worksapce + 'train.tsv', sep = '\\t', names = col)\n",
        "test_data = pd.read_csv(worksapce + 'test.tsv', sep = '\\t', names = col)\n",
        "val_data = pd.read_csv(worksapce + 'valid.tsv', sep = '\\t', names = col)\n",
        "\n",
        "# Replace NaN values with 'NaN'\n",
        "train_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']] = train_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']].fillna(0)\n",
        "train_data.fillna('NaN', inplace=True)\n",
        "\n",
        "test_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']] = test_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']].fillna(0)\n",
        "test_data.fillna('NaN', inplace=True)\n",
        "\n",
        "val_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']] = val_data[['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']].fillna(0)\n",
        "val_data.fillna('NaN', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def textProcess(input_text, max_length = -1):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    if max_length == -1:\n",
        "        tokens = tokenizer(input_text, truncation=True, padding=True)\n",
        "    else:\n",
        "        tokens = tokenizer(input_text, truncation=True, padding='max_length', max_length=max_length)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "\n",
        "# Define a custom dataset for loading the data\n",
        "class LiarDataset(data.Dataset):\n",
        "    def __init__(self, data_df, statement, label_onehot, label, subject, speaker, job_title, state_info,\n",
        "                     party_affiliation, barely_true_counts, false_counts, half_true_counts, mostly_true_counts,\n",
        "                    pants_on_fire_counts, context):\n",
        "        self.data_df = data_df\n",
        "        self.statement = statement\n",
        "        self.label_onehot = label_onehot\n",
        "        self.label = label\n",
        "        self.metadata_text = torch.cat((subject.int(), speaker.int(), job_title.int(), state_info.int(), party_affiliation.int(),\n",
        "                                   context.int()), dim=-1)\n",
        "        self.metadata_number = torch.cat((torch.tensor(barely_true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(false_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(half_true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(mostly_true_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(pants_on_fire_counts, dtype=torch.float).unsqueeze(1)), dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        statement = self.statement[idx]\n",
        "        label_onehot = self.label_onehot[idx]\n",
        "        label = self.label[idx]\n",
        "        metadata_text = self.metadata_text[idx]\n",
        "        metadata_number = self.metadata_number[idx]\n",
        "        return statement, label_onehot, label, metadata_text, metadata_number\n",
        "\n",
        "\n",
        "# Define the data loaders for training and validation\n",
        "train_text = torch.tensor(textProcess(train_data['statement'].tolist())['input_ids'])\n",
        "train_label = torch.nn.functional.one_hot(torch.tensor(train_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "train_subject = torch.tensor(textProcess(train_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_speaker = torch.tensor(textProcess(train_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_job_title = torch.tensor(textProcess(train_data['job_title'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_state_info = torch.tensor(textProcess(train_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_party_affiliation = torch.tensor(textProcess(train_data['party_affiliation'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_context = torch.tensor(textProcess(train_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "train_dataset = LiarDataset(train_data, train_text, train_label, torch.tensor(train_data['label'].replace(label_convert)),\n",
        "                            train_subject, train_speaker, train_job_title,\n",
        "                            train_state_info, train_party_affiliation,\n",
        "                            train_data['barely_true_counts'].tolist(), train_data['false_counts'].tolist(),\n",
        "                            train_data['half_true_counts'].tolist(), train_data['mostly_true_counts'].tolist(),\n",
        "                            train_data['pants_on_fire_counts'].tolist(), train_context)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_text = torch.tensor(textProcess(val_data['statement'].tolist())['input_ids'])\n",
        "val_label = torch.nn.functional.one_hot(torch.tensor(val_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "val_subject = torch.tensor(textProcess(val_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_speaker = torch.tensor(textProcess(val_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_job_title = torch.tensor(textProcess(val_data['job_title'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_state_info = torch.tensor(textProcess(val_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_party_affiliation = torch.tensor(textProcess(val_data['party_affiliation'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_context = torch.tensor(textProcess(val_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "val_dataset = LiarDataset(val_data, val_text, val_label, torch.tensor(val_data['label'].replace(label_convert)),\n",
        "                          val_subject, val_speaker, val_job_title,\n",
        "                          val_state_info, val_party_affiliation,\n",
        "                          val_data['barely_true_counts'].tolist(), val_data['false_counts'].tolist(),\n",
        "                          val_data['half_true_counts'].tolist(), val_data['mostly_true_counts'].tolist(),\n",
        "                          val_data['pants_on_fire_counts'].tolist(), val_context)\n",
        "val_loader = data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "test_text = torch.tensor(textProcess(test_data['statement'].tolist())['input_ids'])\n",
        "test_label = torch.nn.functional.one_hot(torch.tensor(test_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "test_subject = torch.tensor(textProcess(test_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_speaker = torch.tensor(textProcess(test_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_job_title = torch.tensor(textProcess(test_data['job_title'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_state_info = torch.tensor(textProcess(test_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_party_affiliation = torch.tensor(textProcess(test_data['party_affiliation'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_context = torch.tensor(textProcess(test_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "test_dataset = LiarDataset(test_data, test_text, test_label, torch.tensor(test_data['label'].replace(label_convert)),\n",
        "                          test_subject, test_speaker, test_job_title,\n",
        "                          test_state_info, test_party_affiliation,\n",
        "                          test_data['barely_true_counts'].tolist(), test_data['false_counts'].tolist(),\n",
        "                          test_data['half_true_counts'].tolist(), test_data['mostly_true_counts'].tolist(),\n",
        "                          test_data['pants_on_fire_counts'].tolist(), test_context)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "class FuzzyLayer(nn.Module):\n",
        "    def __init__(self, input_dim, membership_num):\n",
        "        super(FuzzyLayer, self).__init__()\n",
        "\n",
        "        # input_dim: feature number of the dataset\n",
        "        # membership_num: number of membership function, also known as the class number\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.membership_num = membership_num\n",
        "\n",
        "        self.membership_miu = nn.Parameter(torch.Tensor(self.membership_num, self.input_dim).to(DEVICE), requires_grad=True)\n",
        "        self.membership_sigma = nn.Parameter(torch.Tensor(self.membership_num, self.input_dim).to(DEVICE), requires_grad=True)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.membership_miu)\n",
        "        nn.init.ones_(self.membership_sigma)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        batch_size = input_seq.size()[0]\n",
        "        input_seq_exp = input_seq.unsqueeze(1).expand(batch_size, self.membership_num, self.input_dim)\n",
        "        membership_miu_exp = self.membership_miu.unsqueeze(0).expand(batch_size, self.membership_num, self.input_dim)\n",
        "        membership_sigma_exp = self.membership_sigma.unsqueeze(0).expand(batch_size, self.membership_num, self.input_dim)\n",
        "\n",
        "        fuzzy_membership = torch.mean(torch.exp((-1 / 2) * ((input_seq_exp - membership_miu_exp) / membership_sigma_exp) ** 2), dim=-1)\n",
        "        return fuzzy_membership\n",
        "\n",
        "\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = embedding_dim,\n",
        "                                              out_channels = n_filters,\n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        #text = [batch size, sent len]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        #embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        #pooled_n = [batch size, n_filters]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n",
        "class CNNBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Linear(input_dim, embedding_dim)\n",
        "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=32, kernel_size=1)\n",
        "        self.rnn = nn.LSTM(32,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, metadata):\n",
        "        #metadata = [batch size, metadata dim]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(metadata))\n",
        "        #embedded = [batch size, metadata dim, emb dim]\n",
        "\n",
        "        embedded = torch.reshape(embedded, (metadata.size(0), 128, 1))\n",
        "\n",
        "        conved = F.relu(self.conv(embedded))\n",
        "        #conved = [batch size, n_filters, metadata dim - filter_sizes[n] + 1]\n",
        "\n",
        "        conved = torch.reshape(conved, (metadata.size(0), 32))\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(conved)\n",
        "        #outputs = [metadata dim - filter_sizes[n] + 1, batch size, hid dim * num directions]\n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        # hidden = self.dropout(torch.cat((hidden[-1,:], hidden[0,:]), dim = -1))\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(outputs)\n",
        "\n",
        "\n",
        "class LiarModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx, input_dim, input_dim_metadata, hidden_dim, n_layers, bidirectional):\n",
        "        super().__init__()\n",
        "\n",
        "        self.textcnn = TextCNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx)\n",
        "        self.textcnn2 = TextCNN(vocab_size, input_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx)\n",
        "        self.cnn_bilstm = CNNBiLSTM(input_dim_metadata, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)\n",
        "        self.fuzzy = FuzzyLayer(output_dim, output_dim)\n",
        "        self.fuse = nn.Linear(output_dim * 4, output_dim)\n",
        "\n",
        "    def forward(self, text, metadata_text, metadata_number):\n",
        "        #text = [batch size, sent len]\n",
        "        #metadata = [batch size, metadata dim]\n",
        "\n",
        "        text_output = self.textcnn(text)\n",
        "        metadata_output_text = self.textcnn2(metadata_text)\n",
        "        metadata_output_number = self.cnn_bilstm(metadata_number)\n",
        "        metadata_output_fuzzy = self.fuzzy(metadata_output_number)\n",
        "\n",
        "        fused_output = self.fuse(torch.cat((text_output, metadata_output_text, metadata_output_number, metadata_output_fuzzy), dim=1))\n",
        "\n",
        "        return fused_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = 30522\n",
        "embedding_dim = 128\n",
        "n_filters = 128\n",
        "filter_sizes = [3,4,5]\n",
        "output_dim = 6\n",
        "dropout = 0.5\n",
        "padding_idx = 0\n",
        "input_dim = 6 * metadata_each_dim\n",
        "input_dim_metadata = 5\n",
        "hidden_dim = 64\n",
        "n_layers = 1\n",
        "bidirectional = True\n",
        "\n",
        "model = LiarModel(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx, input_dim, input_dim_metadata, hidden_dim, n_layers, bidirectional).to(DEVICE)\n",
        "\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "# Record the training process\n",
        "Train_acc = []\n",
        "Train_loss = []\n",
        "Train_macro_f1 = []\n",
        "Train_micro_f1 = []\n",
        "\n",
        "Val_acc = []\n",
        "Val_loss = []\n",
        "Val_macro_f1 = []\n",
        "Val_micro_f1 = []\n",
        "\n",
        "def train(num_epochs, model, train_loader, val_loader, optimizer, criterion, model_save):\n",
        "    epoch_trained = 0\n",
        "    train_label_all = []\n",
        "    train_predict_all = []\n",
        "    val_label_all = []\n",
        "    val_predict_all = []\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_trained += 1\n",
        "        epoch_start_time = time.time()\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_accuracy = 0.0\n",
        "        for statements, label_onehot, label, metadata_text, metadata_number in train_loader:\n",
        "            statements = statements.to(DEVICE)\n",
        "            label_onehot = label_onehot.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            metadata_text = metadata_text.to(DEVICE)\n",
        "            metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(statements, metadata_text, metadata_number)\n",
        "            loss = criterion(outputs, label_onehot)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, train_predicted = torch.max(outputs, 1)\n",
        "            train_accuracy += sum(train_predicted == label)\n",
        "            train_predict_all += train_predicted.tolist()\n",
        "            train_label_all += label.tolist()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy /= len(train_loader.dataset)\n",
        "        train_macro_f1 = f1_score(train_label_all, train_predict_all, average='macro')\n",
        "        train_micro_f1 = f1_score(train_label_all, train_predict_all, average='micro')\n",
        "\n",
        "        Train_acc.append(train_accuracy.tolist())\n",
        "        Train_loss.append(train_loss)\n",
        "        Train_macro_f1.append(train_macro_f1)\n",
        "        Train_micro_f1.append(train_micro_f1)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_accuracy = 0.0\n",
        "        with torch.no_grad():\n",
        "            for statements, label_onehot, label, metadata_text, metadata_number in val_loader:\n",
        "                statements = statements.to(DEVICE)\n",
        "                label_onehot = label_onehot.to(DEVICE)\n",
        "                label = label.to(DEVICE)\n",
        "                metadata_text = metadata_text.to(DEVICE)\n",
        "                metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "                val_outputs = model(statements, metadata_text, metadata_number)\n",
        "                val_loss += criterion(val_outputs, label_onehot).item()\n",
        "                _, val_predicted = torch.max(val_outputs, 1)\n",
        "                val_accuracy += sum(val_predicted == label)\n",
        "                val_predict_all += val_predicted.tolist()\n",
        "                val_label_all += label.tolist()\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy /= len(val_loader.dataset)\n",
        "        val_macro_f1 = f1_score(val_label_all, val_predict_all, average='macro')\n",
        "        val_micro_f1 = f1_score(val_label_all, val_predict_all, average='micro')\n",
        "\n",
        "        Val_acc.append(val_accuracy.tolist())\n",
        "        Val_loss.append(val_loss)\n",
        "        Val_macro_f1.append(val_macro_f1)\n",
        "        Val_micro_f1.append(val_micro_f1)\n",
        "\n",
        "        if val_loss < best_valid_loss:\n",
        "            best_valid_loss = val_loss\n",
        "            torch.save(model.state_dict(), model_save)\n",
        "            print(f'***** Best Result Updated at Epoch {epoch_trained}, Val Loss: {val_loss:.4f} *****')\n",
        "\n",
        "        # Print the losses and accuracy\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train F1 Macro: {train_macro_f1:.4f}, Train F1 Micro: {train_micro_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1 Macro: {val_macro_f1:.4f}, Val F1 Micro: {val_micro_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f'Total Training Time: {training_time:.2f}s')\n",
        "\n",
        "\n",
        "train(num_epochs, model, train_loader, val_loader, optimizer, criterion, model_save)\n",
        "\n",
        "\n",
        "# Evaluate the model on new data\n",
        "def test(model, test_loader, model_save):\n",
        "    model.load_state_dict(torch.load(model_save))\n",
        "    model.eval()\n",
        "\n",
        "    test_label_all = []\n",
        "    test_predict_all = []\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for statements, label_onehot, label, metadata_text, metadata_number in test_loader:\n",
        "            statements = statements.to(DEVICE)\n",
        "            label_onehot = label_onehot.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            metadata_text = metadata_text.to(DEVICE)\n",
        "            metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "            test_outputs = model(statements, metadata_text, metadata_number)\n",
        "            test_loss += criterion(test_outputs, label_onehot).item()\n",
        "            _, test_predicted = torch.max(test_outputs, 1)\n",
        "\n",
        "            test_accuracy += sum(test_predicted == label)\n",
        "            test_predict_all += test_predicted.tolist()\n",
        "            test_label_all += label.tolist()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy /= len(test_loader.dataset)\n",
        "    test_macro_f1 = f1_score(test_label_all, test_predict_all, average='macro')\n",
        "    test_micro_f1 = f1_score(test_label_all, test_predict_all, average='micro')\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}, Test F1 Macro: {test_macro_f1:.4f}, Test F1 Micro: {test_micro_f1:.4f}')\n",
        "\n",
        "\n",
        "test(model, test_loader, model_save)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlT-Q_tZFtdV",
        "outputId": "b7abb67d-2cf4-441f-d35b-0ad54b544ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing the randomness of CUDA.\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"PyTorch Version : {}\".format(torch.__version__))\n",
        "print(DEVICE)\n",
        "\n",
        "\n",
        "worksapce = ''\n",
        "model_save = 'BT+TC+CB+FZ.pt'\n",
        "model_name = 'BT+TC+CB+FZ'\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "num_classes = 6\n",
        "padding_idx = 0\n",
        "metadata_each_dim = 10\n",
        "\n",
        "\n",
        "# col = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
        "col = [\"id\", \"label\", \"statement\", \"date\", \"subject\", \"speaker\", \"speaker_description\", \"state_info\", \"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\", \"context\", \"justification\"]\n",
        "\n",
        "label_map = {0: 'pants-fire', 1: 'false', 2: 'barely-true', 3: 'half-true', 4: 'mostly-true', 5: 'true'}\n",
        "label_convert = {'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true':5}\n",
        "\n",
        "train_data = pd.read_csv(worksapce + 'train.csv')\n",
        "test_data = pd.read_csv(worksapce + 'test.csv')\n",
        "val_data = pd.read_csv(worksapce + 'valid.csv')\n",
        "\n",
        "# Replace NaN values with 'NaN'\n",
        "train_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]] = train_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]].fillna(0)\n",
        "train_data.fillna('NaN', inplace=True)\n",
        "\n",
        "test_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]] = test_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]].fillna(0)\n",
        "test_data.fillna('NaN', inplace=True)\n",
        "\n",
        "val_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]] = val_data[[\"true_counts\", \"mostly_true_counts\", \"half_true_counts\", \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\"]].fillna(0)\n",
        "val_data.fillna('NaN', inplace=True)\n",
        "\n",
        "# Tokenizing text\n",
        "def textProcess(input_text, max_length = -1):\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    if max_length == -1:\n",
        "        tokens = tokenizer(input_text, truncation=True, padding=True)\n",
        "    else:\n",
        "        tokens = tokenizer(input_text, truncation=True, padding='max_length', max_length=max_length)\n",
        "    return tokens\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnRFk400aYFU",
        "outputId": "99d86a0f-7b2e-4bb4-8d5d-274c84d59360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version : 2.6.0+cu124\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset for loading the data\n",
        "class LiarDataset(data.Dataset):\n",
        "    def __init__(self, data_df, statement, statement_mask, label_onehot, label, subject, speaker, job_title, state_info,\n",
        "                     party_affiliation, barely_true_counts, false_counts, half_true_counts, mostly_true_counts,\n",
        "                    pants_on_fire_counts, context):\n",
        "        self.data_df = data_df\n",
        "        self.statement = statement\n",
        "        self.statement_mask = statement_mask\n",
        "        self.label_onehot = label_onehot\n",
        "        self.label = label\n",
        "        self.metadata_text = torch.cat((subject.int(), speaker.int(), job_title.int(), state_info.int(), party_affiliation.int(),\n",
        "                                   context.int()), dim=-1)\n",
        "        self.metadata_number = torch.cat((torch.tensor(barely_true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(false_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(half_true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(mostly_true_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(pants_on_fire_counts, dtype=torch.float).unsqueeze(1)), dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        statement = self.statement[idx]\n",
        "        statement_mask = self.statement_mask[idx]\n",
        "        label_onehot = self.label_onehot[idx]\n",
        "        label = self.label[idx]\n",
        "        metadata_text = self.metadata_text[idx]\n",
        "        metadata_number = self.metadata_number[idx]\n",
        "        return statement, statement_mask, label_onehot, label, metadata_text, metadata_number\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vU2_emnbbQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset for loading the data\n",
        "class LiarDataset(data.Dataset):\n",
        "    def __init__(self, data_df, statement, label_onehot, label, date, subject, speaker, speaker_description, state_info,\n",
        "                    true_counts, mostly_true_counts, half_true_counts, mostly_false_counts,\n",
        "                    false_counts, pants_on_fire_counts, context, justification):\n",
        "        self.data_df = data_df\n",
        "        self.statement = statement\n",
        "        self.label_onehot = label_onehot\n",
        "        self.label = label\n",
        "        self.justification = justification\n",
        "        self.metadata_text = torch.cat((date.int(), subject.int(), speaker.int(), speaker_description.int(), state_info.int(), context.int()), dim=-1)\n",
        "        self.metadata_number = torch.cat((torch.tensor(true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(mostly_true_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(half_true_counts, dtype=torch.float).unsqueeze(1), torch.tensor(mostly_false_counts, dtype=torch.float).unsqueeze(1),\n",
        "                                   torch.tensor(false_counts, dtype=torch.float).unsqueeze(1), torch.tensor(pants_on_fire_counts, dtype=torch.float).unsqueeze(1)), dim=-1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        statement = self.statement[idx]\n",
        "        label_onehot = self.label_onehot[idx]\n",
        "        label = self.label[idx]\n",
        "        justification = self.justification[idx]\n",
        "        metadata_text = self.metadata_text[idx]\n",
        "        metadata_number = self.metadata_number[idx]\n",
        "        return statement, label_onehot, label, metadata_text, metadata_number, justification\n",
        "\n",
        "\n",
        "# Define the data loaders for training and validation\n",
        "train_text = torch.tensor(textProcess(train_data['statement'].tolist())['input_ids'])\n",
        "train_justification = torch.tensor(textProcess(train_data['justification'].tolist())['input_ids'])\n",
        "train_label = torch.nn.functional.one_hot(torch.tensor(train_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "train_date = torch.tensor(textProcess(train_data['date'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_subject = torch.tensor(textProcess(train_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_speaker = torch.tensor(textProcess(train_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_speaker_description = torch.tensor(textProcess(train_data['speaker_description'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_state_info = torch.tensor(textProcess(train_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "train_context = torch.tensor(textProcess(train_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "train_dataset = LiarDataset(train_data, train_text, train_label, torch.tensor(train_data['label'].replace(label_convert)),\n",
        "                            train_date, train_subject, train_speaker, train_speaker_description, train_state_info,\n",
        "                            train_data['true_counts'].tolist(), train_data['mostly_true_counts'].tolist(),\n",
        "                            train_data['half_true_counts'].tolist(), train_data['mostly_false_counts'].tolist(),\n",
        "                            train_data['false_counts'].tolist(), train_data['pants_on_fire_counts'].tolist(), train_context, train_justification)\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_text = torch.tensor(textProcess(val_data['statement'].tolist())['input_ids'])\n",
        "val_justification = torch.tensor(textProcess(val_data['justification'].tolist())['input_ids'])\n",
        "val_label = torch.nn.functional.one_hot(torch.tensor(val_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "val_date = torch.tensor(textProcess(val_data['date'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_subject = torch.tensor(textProcess(val_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_speaker = torch.tensor(textProcess(val_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_speaker_description = torch.tensor(textProcess(val_data['speaker_description'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_state_info = torch.tensor(textProcess(val_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "val_context = torch.tensor(textProcess(val_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "val_dataset = LiarDataset(val_data, val_text, val_label, torch.tensor(val_data['label'].replace(label_convert)),\n",
        "                          val_date, val_subject, val_speaker, val_speaker_description, val_state_info,\n",
        "                          val_data['true_counts'].tolist(), val_data['mostly_true_counts'].tolist(),\n",
        "                          val_data['half_true_counts'].tolist(), val_data['mostly_false_counts'].tolist(),\n",
        "                          val_data['false_counts'].tolist(), val_data['pants_on_fire_counts'].tolist(), val_context, val_justification)\n",
        "val_loader = data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "test_text = torch.tensor(textProcess(test_data['statement'].tolist())['input_ids'])\n",
        "test_justification = torch.tensor(textProcess(test_data['justification'].tolist())['input_ids'])\n",
        "test_label = torch.nn.functional.one_hot(torch.tensor(test_data['label'].replace(label_convert)), num_classes=6).type(torch.float64)\n",
        "test_date = torch.tensor(textProcess(test_data['date'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_subject = torch.tensor(textProcess(test_data['subject'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_speaker = torch.tensor(textProcess(test_data['speaker'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_speaker_description = torch.tensor(textProcess(test_data['speaker_description'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_state_info = torch.tensor(textProcess(test_data['state_info'].tolist(), metadata_each_dim)['input_ids'])\n",
        "test_context = torch.tensor(textProcess(test_data['context'].tolist(), metadata_each_dim)['input_ids'])\n",
        "\n",
        "test_dataset = LiarDataset(test_data, test_text, test_label, torch.tensor(test_data['label'].replace(label_convert)),\n",
        "                          test_date, test_subject, test_speaker, test_speaker_description, test_state_info,\n",
        "                          test_data['true_counts'].tolist(), test_data['mostly_true_counts'].tolist(),\n",
        "                          test_data['half_true_counts'].tolist(), test_data['mostly_false_counts'].tolist(),\n",
        "                          test_data['false_counts'].tolist(), test_data['pants_on_fire_counts'].tolist(), test_context, test_justification)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "V8gwJbXPbTx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, membership_num):\n",
        "        super(FuzzyLayer, self).__init__()\n",
        "\n",
        "#         input_dim: feature number of the dataset\n",
        "#         membership_num: number of membership function, also known as the class number\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.membership_num = membership_num\n",
        "\n",
        "        self.membership_miu = nn.Parameter(torch.Tensor(self.membership_num, self.input_dim).to(DEVICE), requires_grad=True)\n",
        "        self.membership_sigma = nn.Parameter(torch.Tensor(self.membership_num, self.input_dim).to(DEVICE), requires_grad=True)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.membership_miu)\n",
        "        nn.init.ones_(self.membership_sigma)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        batch_size = input_seq.size()[0]\n",
        "        input_seq_exp = input_seq.unsqueeze(1).expand(batch_size, self.membership_num, self.input_dim)\n",
        "        membership_miu_exp = self.membership_miu.unsqueeze(0).expand(batch_size, self.membership_num, self.input_dim)\n",
        "        membership_sigma_exp = self.membership_sigma.unsqueeze(0).expand(batch_size, self.membership_num, self.input_dim)\n",
        "\n",
        "        fuzzy_membership = torch.mean(torch.exp((-1 / 2) * ((input_seq_exp - membership_miu_exp) / membership_sigma_exp) ** 2), dim=-1)\n",
        "        return fuzzy_membership\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aKAUTf6xbYLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([\n",
        "                                    nn.Conv1d(in_channels = embedding_dim,\n",
        "                                              out_channels = n_filters,\n",
        "                                              kernel_size = fs)\n",
        "                                    for fs in filter_sizes\n",
        "                                    ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        #text = [batch size, sent len]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "        #embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
        "\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        #pooled_n = [batch size, n_filters]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n"
      ],
      "metadata": {
        "id": "okLehGz1bbUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Linear(input_dim, embedding_dim)\n",
        "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=32, kernel_size=1)\n",
        "        self.rnn = nn.LSTM(32,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, metadata):\n",
        "        #metadata = [batch size, metadata dim]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(metadata))\n",
        "        #embedded = [batch size, metadata dim, emb dim]\n",
        "\n",
        "        embedded = torch.reshape(embedded, (metadata.size(0), 128, 1))\n",
        "\n",
        "        conved = F.relu(self.conv(embedded))\n",
        "        #conved = [batch size, n_filters, metadata dim - filter_sizes[n] + 1]\n",
        "\n",
        "        conved = torch.reshape(conved, (metadata.size(0), 32))\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(conved)\n",
        "        #outputs = [metadata dim - filter_sizes[n] + 1, batch size, hid dim * num directions]\n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        # hidden = self.dropout(torch.cat((hidden[-1,:], hidden[0,:]), dim = -1))\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(outputs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IOVAyRjHbeV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LiarModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx, input_dim, input_dim_metadata, hidden_dim, n_layers, bidirectional):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=output_dim)\n",
        "        self.textcnn2 = TextCNN(vocab_size, input_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx)\n",
        "        self.cnn_bilstm = CNNBiLSTM(input_dim_metadata, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout)\n",
        "        self.fuzzy = FuzzyLayer(output_dim, output_dim)\n",
        "        self.fuse = nn.Linear(output_dim * 4, output_dim)\n",
        "\n",
        "    def forward(self, text, text_masks, metadata_text, metadata_number):\n",
        "        #text = [batch size, sent len]\n",
        "        #metadata = [batch size, metadata dim]\n",
        "\n",
        "        text_output = self.bert(text, text_masks)[0]\n",
        "        metadata_output_text = self.textcnn2(metadata_text)\n",
        "        metadata_output_number = self.cnn_bilstm(metadata_number)\n",
        "        metadata_output_fuzzy = self.fuzzy(metadata_output_number)\n",
        "\n",
        "        fused_output = self.fuse(torch.cat((text_output, metadata_output_text, metadata_output_number, metadata_output_fuzzy), dim=1))\n",
        "\n",
        "        return fused_output\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I9WQPoI3bhYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size = 30522\n",
        "embedding_dim = 128\n",
        "n_filters = 128\n",
        "filter_sizes = [3,4,5]\n",
        "output_dim = 6\n",
        "dropout = 0.5\n",
        "padding_idx = 0\n",
        "input_dim = 6 * metadata_each_dim\n",
        "input_dim_metadata = 5\n",
        "hidden_dim = 64\n",
        "n_layers = 2\n",
        "bidirectional = True\n",
        "\n",
        "model = LiarModel(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, padding_idx, input_dim, input_dim_metadata, hidden_dim, n_layers, bidirectional).to(DEVICE)\n",
        "\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "# Record the training process\n",
        "Train_acc = []\n",
        "Train_loss = []\n",
        "Train_macro_f1 = []\n",
        "Train_micro_f1 = []\n",
        "\n",
        "Val_acc = []\n",
        "Val_loss = []\n",
        "Val_macro_f1 = []\n",
        "Val_micro_f1 = []\n",
        "\n"
      ],
      "metadata": {
        "id": "8PVZUAAIbkaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, train_loader, val_loader, optimizer, criterion, model_save):\n",
        "    epoch_trained = 0\n",
        "    train_label_all = []\n",
        "    train_predict_all = []\n",
        "    val_label_all = []\n",
        "    val_predict_all = []\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_trained += 1\n",
        "        epoch_start_time = time.time()\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_accuracy = 0.0\n",
        "        for statements, statement_mask, label_onehot, label, metadata_text, metadata_number in train_loader:\n",
        "            statements = statements.to(DEVICE)\n",
        "            statement_mask = statement_mask.to(DEVICE)\n",
        "            label_onehot = label_onehot.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            metadata_text = metadata_text.to(DEVICE)\n",
        "            metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(statements, statement_mask, metadata_text, metadata_number)\n",
        "            loss = criterion(outputs, label_onehot)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, train_predicted = torch.max(outputs, 1)\n",
        "            train_accuracy += sum(train_predicted == label)\n",
        "            train_predict_all += train_predicted.tolist()\n",
        "            train_label_all += label.tolist()\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy /= len(train_loader.dataset)\n",
        "        train_macro_f1 = f1_score(train_label_all, train_predict_all, average='macro')\n",
        "        train_micro_f1 = f1_score(train_label_all, train_predict_all, average='micro')\n",
        "\n",
        "        Train_acc.append(train_accuracy.tolist())\n",
        "        Train_loss.append(train_loss)\n",
        "        Train_macro_f1.append(train_macro_f1)\n",
        "        Train_micro_f1.append(train_micro_f1)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_accuracy = 0.0\n",
        "        with torch.no_grad():\n",
        "            for statements, statement_mask, label_onehot, label, metadata_text, metadata_number in val_loader:\n",
        "                statements = statements.to(DEVICE)\n",
        "                statement_mask = statement_mask.to(DEVICE)\n",
        "                label_onehot = label_onehot.to(DEVICE)\n",
        "                label = label.to(DEVICE)\n",
        "                metadata_text = metadata_text.to(DEVICE)\n",
        "                metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "                val_outputs = model(statements, statement_mask, metadata_text, metadata_number)\n",
        "                val_loss += criterion(val_outputs, label_onehot).item()\n",
        "                _, val_predicted = torch.max(val_outputs, 1)\n",
        "                val_accuracy += sum(val_predicted == label)\n",
        "                val_predict_all += val_predicted.tolist()\n",
        "                val_label_all += label.tolist()\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy /= len(val_loader.dataset)\n",
        "        val_macro_f1 = f1_score(val_label_all, val_predict_all, average='macro')\n",
        "        val_micro_f1 = f1_score(val_label_all, val_predict_all, average='micro')\n",
        "\n",
        "        Val_acc.append(val_accuracy.tolist())\n",
        "        Val_loss.append(val_loss)\n",
        "        Val_macro_f1.append(val_macro_f1)\n",
        "        Val_micro_f1.append(val_micro_f1)\n",
        "\n",
        "        if val_loss < best_valid_loss:\n",
        "            best_valid_loss = val_loss\n",
        "            torch.save(model.state_dict(), model_save)\n",
        "            print(f'***** Best Result Updated at Epoch {epoch_trained}, Val Loss: {val_loss:.4f} *****')\n",
        "\n",
        "        # Print the losses and accuracy\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_time = epoch_end_time - epoch_start_time\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train F1 Macro: {train_macro_f1:.4f}, Train F1 Micro: {train_micro_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1 Macro: {val_macro_f1:.4f}, Val F1 Micro: {val_micro_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f'Total Training Time: {training_time:.2f}s')\n",
        "\n",
        "\n",
        "train(num_epochs, model, train_loader, val_loader, optimizer, criterion, model_save)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2SLnTs2jboJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on new data\n",
        "def test(model, test_loader, model_save):\n",
        "    model.load_state_dict(torch.load(model_save))\n",
        "    model.eval()\n",
        "\n",
        "    test_label_all = []\n",
        "    test_predict_all = []\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for statements, statement_mask, label_onehot, label, metadata_text, metadata_number in test_loader:\n",
        "            statements = statements.to(DEVICE)\n",
        "            statement_mask = statement_mask.to(DEVICE)\n",
        "            label_onehot = label_onehot.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            metadata_text = metadata_text.to(DEVICE)\n",
        "            metadata_number = metadata_number.to(DEVICE)\n",
        "\n",
        "            test_outputs = model(statements, statement_mask, metadata_text, metadata_number)\n",
        "            test_loss += criterion(test_outputs, label_onehot).item()\n",
        "            _, test_predicted = torch.max(test_outputs, 1)\n",
        "\n",
        "            test_accuracy += sum(test_predicted == label)\n",
        "            test_predict_all += test_predicted.tolist()\n",
        "            test_label_all += label.tolist()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy /= len(test_loader.dataset)\n",
        "    test_macro_f1 = f1_score(test_label_all, test_predict_all, average='macro')\n",
        "    test_micro_f1 = f1_score(test_label_all, test_predict_all, average='micro')\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}, Test F1 Macro: {test_macro_f1:.4f}, Test F1 Micro: {test_micro_f1:.4f}')\n",
        "\n",
        "\n",
        "test(model, test_loader, model_save)"
      ],
      "metadata": {
        "id": "s3oG8kWFbrW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uf5LnzbOuAyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}